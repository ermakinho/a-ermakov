# HW07 – Report


## 1. Datasets

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: `12000x9`
- Признаки: 8 числовых признаков и `sample_id` в качестве индекса
- Пропуски: Отсутсвуют


### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: `8000x4`
- Признаки: 3 числовых признака и `sample_id` в качестве индекса
- Пропуски: Отсутсвуют

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: `15000x5`
- Признаки: 4 числовых признака и `sample_id` в качестве индекса
- Пропуски: Отсутсвуют

## 2. Protocol


- Препроцессинг: удаление `sample_id` из признаков и `StandartScaler`. `SimpleImputer` и `OneHotEncoder` не понадобились, поскольку пропусков и категориальных переменных нет.
- Поиск гиперпараметров:
   Для поиска гиперпараметров были реализованы функции `cv_n_in_kmeans` и `cv_dbscan_params`, повторяющие по функционалу `GridSearchCV`, используемый в предыдущих практиках + собирающих историю прохода по гиперпараметрам для графиков и json-артефактов.
  - В случае с `KMeans` подбирался параметр `n_clusters`. Было принято решение искать от 2 до 20, т.к. визуально и практически больше кластеров вряд ли будут различимы и иметь ценность.
  - Для `DBSCAN` подбирался параметр `eps` и `min_samples`. `eps` подбирался в диапазоне 0-1 из соображений, что `X` прошёл препроцессинг в `StandartScaler`, а `min_samples` высчитывался взависимости от размеров датасета.
- Метрики: Использовалось всё - Silhouette, Davies-Bouldin, Calinski-Harabasz. Для `DBSCAN` учитывался шум.
- Визуализация: PCA(2D)

## 3. Models

Для каждого датасета были провалидированы `KMeans` и `DBSCAN`, а также построены визуализации и найдены оптимальные гиперпараметры по метрикам + визуально. Были построены визуализации разделения кластеров на обоих методах с наилучшими параметрами.


## 4. Results

Лучшие конфигурации по датасетам

| Датасет | Модель  | Параметры                              | 
|---------|---------|----------------------------------------|
| **ds1** | DBSCAN  | `eps=0.5, min_samples=32`             |
| **ds2** | KMeans | `n_clusters=2, n_init=10, random_state=42` |
| **ds3** | DBSCAN  | `eps=0.32, min_samples=16`            |


### 4.1 Dataset A

- **Лучший метод**: `DBSCAN (eps=0.5, min_samples=32)`
- **Метрики**: Silhouette=**0.417**, DB=1.071, CH=8587
- **Доля шума**: **19.9%** (низкий уровень)
- **Почему**: На PCA, справа, видно скопление множества кластеров, которые из-за своей плотности определяются `KMeans` как один кластер, хотя в нём отчётливо просмтариваются уплотнения. Проблема `KMeans` в данном случае - невозможность обработать сложную форму, по который распределены данные.

### 4.2 Dataset B

- **Лучший метод**: `KMeans (n_clusters=2)`
- **Метрики**: Silhouette=**0.307**, DB=1.323, CH=3573
- **Комментарий**: Однородная структура данных с множеством неплотных вкраплений по краям, которые `DBSCAN` определяет как отдельные кластеры (Silhouette max 0.35). `KMeans` даёт чёткие 2 кластера с приемлемой компактностью, а `DBSCAN` определяет кластеры хаотично. Данный датасет в целом разделяется не очень.
  
### 4.3 Dataset C

- **Лучший метод**: `DBSCAN (eps=0.32, min_samples=16)`
- **Метрики**: Silhouette=**0.248**, DB=1.165, CH=2909
- **Доля шума**: **31.3%**
- **Почему**: Применение `DBSCAN` даёт отчётливые кластеры на PCA (`KMeans` делит визуально заметно хуже) и нормальные показатели метрик.
  
## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans может ломаться на кластерах с трудной формой, поскольку не предназначен для разделения сложнораспределённых в простарнстве данных. Хорош для "шариков" со схожими плотностями и размерами. Центроиды тянутся к середине, разрывая нелинейные структуры.
- `DBSCAN` как раз таки в таких случаях даёт лучший результат за счёт своего алгоритма основанного на испоьлзовании плотности. Он может определять кластеры разной формы (месяцы, окружности и т.п.), а также дополнительно умеет искать шум.
- На результаты работы:
    -  Критически важно повлияло масшабирование - без `StandartScaler` признаки в разной шкале ломают расстояние.
    -  Плотность - важна при неоднородности для `DBSCAN`.


### 5.2 Устойчивость (обязательно для одного датасета)

Среднее значение ARI между разными запусками составляет 0.998 ± 0.001, что указывает на почти полное совпадение разметок кластеров при различных random_state.
Значения ARI по всем парам запусков находятся в диапазоне ≈ 0.996 – 1.000, что свидетельствует об отсутствии конкурирующих локальных минимумов.
`KMeans` демонстрирует высокую устойчивость как по структуре кластеров, так и по качеству разбиения, что указывает на наличие стабильной и воспроизводимой кластерной структуры в данных.
**Кластеризация устойчива**: разметки практически идентичны при разных инициализациях (ARI ≈ 0.998), а качество разбиения стабильно и объясняет около 31% общей вариации данных.

### 5.3 Интерпретация кластеров

В результате кластеризации исходные объекты были разделены на несколько групп, внутри которых наблюдения обладают схожими характеристиками, а различия между группами максимальны. Каждый кластер можно интерпретировать как отдельный тип объектов с близкими значениями признаков.

- Кластеры, полученные с помощью KMeans, характеризуются компактностью и близостью объектов к центрам кластеров. Это позволяет интерпретировать каждый кластер через средние значения признаков, которые отражают типичное поведение или свойства объектов, входящих в данный кластер.

- Кластеры, выделенные алгоритмом DBSCAN, отражают естественные плотностные группы в данных. Наличие шумовых объектов указывает на наблюдения, не относящиеся ни к одному устойчивому кластеру, что может быть интерпретировано как аномальные или редкие случаи.

- Сравнение кластеров показывает, что различия между ними обусловлены ключевыми признаками, имеющими наибольший вклад в расстояния между объектами. Это позволяет использовать кластеры для дальнейшего анализа, сегментации данных и выявления характерных групп наблюдений.

## 6. Conclusion

1. **Масштабирование** — первое правило кластеризации, без него всё бессмысленно.
2. **KMeans** работает только на сферических кластерах равной плотности, на сложных формах ломается.
3. **DBSCAN** автоматически находит шум и нелинейные структуры — идеален для реальных данных (где 20-30% шума = норма).
4. **Silhouette** — отправная точка, но нужен комплекс: **DB + CH + визуализация + устойчивость**.
5. **ARI ≈ 1.0 и Inertia Ratio** подтверждает стабильность разбиения — обязательная проверка для KMeans, показывает практическую полезность кластеризации (30% объяснённой вариации = хорошо).
6. **Нет универсального алгоритма** — подбираем под данные: простые структуры => KMeans, сложные => DBSCAN.
