# HW06 – Report

## 1. Dataset

- Выбран датасет `S06-hw-dataset-01.csv`
- Размер `(12000 x 30)`
- Целевая переменная: `target` имеет классы `0` (68%) и `1` (32%)
- Признаки: `num01`, ..., `num24`, `cat_contract`, `cat_region`, `cat_payment`, `tenure_months`. Все признаки числовые (Есть также порядковый `id`, который не учавствует в обучении)

## 2. Protocol
- Датасет случайным образом был разбит на train и test выборку в соотношении 80% на 20% с seed-ом = 42. Т.к. в датасете есть дисбаланс классов, также использовался параметр stratify
- Подбор гиперпараметров осуществалялся с помощью `GridSearchCV` на train (9600 строк) - 3 фолда, оптимизация по `ROC-AUC`.
- Метрики:
  - `Accuracy`: доля правильных предсказаний
  - `F1-score`: гармоническое среднее precision/recall (учитывает дисбаланс)
  - `ROC-AUC`: устойчив к дисбалансу, независим от порога классификации, идеален для CV

## 3. Models

В ходе работы, для решения данной задачи, мною были опробованы 5 моделей. 
Две из них выступили бейзлайнами:

| Модель             | Параметры                |
| ------------------ | ------------------------ |
| DummyClassifier    | strategy='most_frequent' |
| LogisticRegression | C=1.0, max_iter=1000     |

Также 3 модели, которые прошли кросс-валдиацию

| Модель                     | Подбираемые параметры                                            | Лучшие параметры                                 |
| -------------------------- | ---------------------------------------------------------------- | ------------------------------------------------ |
| DecisionTreeClassifier     | max_depth=[3,5,7,10] min_samples_leaf=[5,10,20]                  | max_depth=5  min_samples_leaf=10                 |
| RandomForestClassifier     | n_estimators=[100,200] max_depth=[5,10] min_samples_leaf=[5,10]  | n_estimators=200 max_depth=10 min_samples_leaf=5 |
| GradientBoostingClassifier | n_estimators=[100,200] max_depth=[5,10] min_samples_leaf=[5,10]  | n_estimators=200 max_depth=5 min_samples_leaf=5  |

## 4. Results

В результате работы моделей получились следующие метрики:

| Модель             | Accuracy | F1-score | ROC-AUC |
| ------------------ | -------- | -------- | ------- |
| DummyClassifier    | 0.677    | 0.000    | 0.500   |
| LogisticRegression | 0.828    | 0.708    | 0.875   |
| DecisionTreeClassifier     | 0.868    | 0.788    | 0.907   |
| RandomForestClassifier     | 0.911    | 0.850    | 0.960   |
| **GradientBoostingClassifier** | 0.938    | 0.901    | **0.972**  |

**GradientBoostingClassifier** — абсолютный лидер по всем метрикам. Он превосходит бейзлайновые модели, а также, в данном случае, Дерево решений и Случайный лес



## 5. Analysis

- Устойчивость:
  Для модели градиентого бустинга с наилучшими параметрами был устроен прогон на разных `random_state`

  
| seed | accuracy | f1    | roc-auc | roc-auc-std | f1-std |
| ---- | -------- | ----- | ------- | ----------- | ------ |
| 42   | 0.938    | 0.901 | 0.972   | 0.0039      | 0.0079 |
| 123  | 0.945    | 0.912 | 0.976   | 0.0039      | 0.0079 |
| 777  | 0.946    | 0.913 | 0.980   | 0.0039      | 0.0079 |
| 100  | 0.950    | 0.921 | 0.982   | 0.0039      | 0.0079 |
| 200  | 0.940    | 0.905 | 0.975   | 0.0039      | 0.0079 |

Модель достаточно стабильна и готова к использованию

- Интерпретация признаков:
    num18/19/07 - три ключевых признака, которые больше всех влияют на работу данной модели.

    - num18 и num19 (0.07) — доминируют
    - num07 (порядка 0.03) — менее значимый

Остальные признаки в массе своей также влияют на принятие решений, однако в гораздо меньшей мере

## 6. Conclusion

- Подбор глубины (10) и количества деревьев (200) критически важен для качества
- Ансамбли устойчивы к шуму благодаря усреднению предсказаний множества базовых моделей
- Градиентный бустинг превосходит Random Forest за счёт последовательного исправления ошибок
- `Permutation importance` даёт интерпретируемость модели